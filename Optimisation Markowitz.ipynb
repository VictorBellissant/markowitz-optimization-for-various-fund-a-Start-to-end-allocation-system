{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716f1c1f-e9a2-4e7f-abe1-3dead95e1394",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veuillez Selectionner l'année de départ pour la fenêtre d'optimisation:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ert\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'ert'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVeuillez Selectionner l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannée de départ pour la fenêtre d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimisation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m année_début \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m()\n\u001b[1;32m----> 4\u001b[0m année_début \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannée_début\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVeuillez Selectionner le mois de départ pour la fenêtre d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimisation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m mois_début \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'ert'"
     ]
    }
   ],
   "source": [
    "# Veuillez renseigner les dates de backtest souhaitées : \n",
    "print(\"Veuillez Selectionner l'année de départ pour la fenêtre d'optimisation:\")\n",
    "année_début = input()\n",
    "année_début = int(année_début)\n",
    "\n",
    "print(\"Veuillez Selectionner le mois de départ pour la fenêtre d'optimisation:\")\n",
    "mois_début = input()\n",
    "mois_début = int(mois_début)\n",
    "\n",
    "print(\"Veuillez Selectionner le jour de départ pour la fenêtre d'optimisation:\")\n",
    "jour_début = input()\n",
    "jour_début = int(jour_début)\n",
    "\n",
    "print(\"Veuillez Selectionner l'année de fin pour la fenêtre d'optimisation:\")\n",
    "année_fin = input()\n",
    "année_fin = int(année_fin)\n",
    "\n",
    "print(\"Veuillez Selectionner le mois de fin pour la fenêtre d'optimisation:\")\n",
    "mois_fin = input()\n",
    "mois_fin = int(mois_fin)\n",
    "\n",
    "print(\"Veuillez Selectionner le jour de fin pour la fenêtre d'optimisation:\")\n",
    "jour_fin = input()\n",
    "jour_fin = int(jour_fin)\n",
    "\n",
    "# Veuillez renseigner la quantité de Short souhaitée : \n",
    "print(\"Veuillez Sélectionner la quantité de short que vous souhaitez avoir lors de l'optimisation (exemple : 0.4 = 40%)\")\n",
    "max_short_trehsold = input()\n",
    "max_short_trehsold = int(max_short_trehsold)\n",
    "\n",
    "# Veuillez renseigner l'optimisation que vous souhaitez : \n",
    "print(\"Veuillez Sélectionner l'optimisation que vous souhaitez : 1 pour un optimisation 93,63 pour un évantaille de MAR, 2 pour une optimisation 93,63 pour un seul MAR, 3 pour l'optimisation classique 63 & 93 avec les MAR habituels\")\n",
    "Choix_optimisation = input()\n",
    "Choix_optimisation = int(Choix_optimisation)\n",
    "\n",
    "# Importation des modules :\n",
    "import openpyxl \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "from pandas.tseries.offsets import BDay\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import style\n",
    "plt.style.use('fivethirtyeight')\n",
    "import os \n",
    "from os import walk\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "color_liste = [\"b\",\"g\",\"r\",\"c\",\"m\",\"y\",\"k\",\"tab:pink\",\"tab:gray\",\"tab:orange\",\"teal\",\"lightgreen\",\"peru\",\"indianred\",\"forestgreen\",\"lemonchiffon\",\"saddlebrown\",\"peachpuff\",\"lightblue\",\"darkgrey\",\"deeppink\",\"violet\"]\n",
    "\n",
    "TODAY = date.today().strftime(\"%Y%m%d\")\n",
    "TODAY = '20221201'\n",
    "\n",
    "directory_path = \"Portefeuilles Directory/\"\n",
    "\n",
    "# Fonction qui permet d'obtenir les liste des portefeuilles à optimiser\n",
    "# Input_Type : None\n",
    "# Output_Type : String_List,String_List\n",
    "def get_lists():\n",
    "    \n",
    "    listeFichiers = []\n",
    "    \n",
    "    for (fichiers) in walk(directory_path):\n",
    "        listeFichiers.extend(fichiers)\n",
    "\n",
    "    portefeuille_name_list = listeFichiers[2]\n",
    "\n",
    "    portefeuille_list = [] \n",
    "    \n",
    "    for value in listeFichiers[2]:\n",
    "        portefeuille_list.append(directory_path + value)\n",
    "        \n",
    "    return portefeuille_list,portefeuille_name_list\n",
    "\n",
    "# Declaration des listes : \n",
    "portefeuille_list,portefeuille_name_list = get_lists()\n",
    "\n",
    "# Construction des filespath pour charger les portefeuilles : (théoriquement, leurs noms contient la date d'aujourd'hui)\n",
    "builded_portefeuille_list = []\n",
    "for portefeuille in portefeuille_name_list:\n",
    "    builded_portefeuille_list.append('{}'.format(TODAY) + \"_\" + portefeuille)\n",
    "    \n",
    "folder_name = \"Dossier_Portefeuilles_crées_convertis/\" \n",
    "\n",
    "directory_list = []\n",
    "for name in builded_portefeuille_list:\n",
    "    directory_list.append(folder_name + name)\n",
    "\n",
    "Liste_for_database_mngt = []\n",
    "for value in portefeuille_name_list:\n",
    "    Liste_for_database_mngt.append(value[:-5])\n",
    "\n",
    "# Création des Dossiers dans lesquels vont être écris les résultats de l'optimisation : \n",
    "import shutil\n",
    "# Suppression des dossiers existant : \n",
    "for k in range(len(Liste_for_database_mngt)):\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Weight matrices\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Statistiques\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Realized returns\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Profils allocation\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Performances VS Equity Curves\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Equity Curves\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Drawdowns\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Absolute returns\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Performances attribution\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Drawdowns csv\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Multiplots_Equity_Curves\")\n",
    "    shutil.rmtree(Liste_for_database_mngt[k] + \"/Multiplots_Drawdowns\")\n",
    "# Création des Dossiers dans lesquels vont être écris les résultats de l'optimisation\n",
    "# Suite au clean de l'arborescence, on re-créer ici l'ensemble des dossiers nécessaire au stockage des résultats : \n",
    "for k in range(len(Liste_for_database_mngt)):\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Weight matrices\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Statistiques\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Realized returns\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Profils allocation\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Performances VS Equity Curves\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Equity Curves\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Drawdowns\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Absolute returns\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Performances attribution\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Drawdowns csv\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Multiplots_Equity_Curves\")\n",
    "    os.mkdir(Liste_for_database_mngt[k] + \"/Multiplots_Drawdowns\") \n",
    "# Construction de la fonction pour obtenir les log returns :\n",
    "# Input_Type : DataFrame\n",
    "# Output_Type : DataFrame of Float\n",
    "def log_ret(portefeuille):\n",
    "    log_return = np.log(portefeuille/portefeuille.shift(1))\n",
    "    return log_return  \n",
    "\n",
    "# Fonction d'obtention des listes de portefeuilles : \n",
    "# Input_Type : DataFrame,int,int\n",
    "# Output_Type : liste,DataFrame,DataFrame,DataFrame_List,DataFrame_List,DataFrame_List,DataFrame_List\n",
    "def prepare_portefeuille(Portefeuille,window_backtest,window_lenght,backtest_starting_date,backtest_ending_date): \n",
    "    \n",
    "    # Préparation des portefeuilles : \n",
    "    portefeuille = Portefeuille.copy()\n",
    "    portefeuille.rename(columns = {\"Unnamed: 0\" : 'Date'},inplace = True)\n",
    "    if \"Date\" in portefeuille.columns:\n",
    "        \n",
    "        portefeuille.set_index(\"Date\",inplace = True)\n",
    "    portefeuille = portefeuille[backtest_starting_date:backtest_ending_date]\n",
    "\n",
    "    # Fill after et fill before des Nan Values :\n",
    "    # Fill before :\n",
    "    Portefeuille_before = portefeuille.ffill(axis = 'rows')\n",
    "    # Fill after :\n",
    "    Portefeuille_after = portefeuille.bfill(axis = 'rows')\n",
    "    \n",
    "    # Pour réaliser les backtest, nous avons besoin de données de la taille de window_backtest avant le premier backtest au minimum :\n",
    "    Portefeuille_before_ = Portefeuille_before[window_backtest + 1:]\n",
    "    # Découpage du portefeuille en une liste de portefeuille de taille window_lenght:\n",
    "    Portefeuille_list = np.array_split(Portefeuille_before_, len(Portefeuille_before_)/window_lenght)\n",
    "    \n",
    "    # Création de l'index_list pour chacuns des portefeuilles :\n",
    "    index_list = [Portefeuille_before.index[window_backtest]]\n",
    "    for k in range (len(Portefeuille_list)-1):\n",
    "        index_list.append(Portefeuille_list[k].index[len(Portefeuille_list[k].index)-1])\n",
    "        \n",
    "    # Création de la liste des portefeuilles bien coupés en bout, coupe à la fin :    \n",
    "    Portefeuille_before_backtest_list = []\n",
    "    for j in range (len(index_list)):\n",
    "        Portefeuille_before_backtest_list.append(Portefeuille_before[:index_list[j]])\n",
    "    Portefeuille_before_backtest_list.append(Portefeuille_before[index_list[len(index_list)-1]:])\n",
    "    \n",
    "    Portefeuille_before_backtest = []\n",
    "    for k in range (len(Portefeuille_before_backtest_list)):\n",
    "        Portefeuille_before_backtest.append(Portefeuille_before_backtest_list[k][-window_backtest:])\n",
    "    \n",
    "    # Création des portefeuilles de log_return pour calculer les poids :\n",
    "    \n",
    "    Log_return_Portefeuille_before_backtest_list = []\n",
    "    for portefeuille in Portefeuille_before_backtest:\n",
    "        Log_return_Portefeuille_before_backtest_list.append(log_ret(portefeuille))\n",
    "        \n",
    "    Log_return_Portefeuille_before_backtest_list = Log_return_Portefeuille_before_backtest_list[:-1]\n",
    "    \n",
    "    Log_return_Portefeuille_before_backtest_list.append(log_ret(Portefeuille_before[-window_backtest:]))\n",
    "        \n",
    "    return index_list,Portefeuille_before,Portefeuille_before_,Portefeuille_list,Portefeuille_before_backtest_list,Portefeuille_before_backtest,Log_return_Portefeuille_before_backtest_list\n",
    "\n",
    "# Fonction de calcul des statistiques annualisée des portefeuilles : \n",
    "# Input_Type : Float_list,DataFrame\n",
    "# Output_Type : Array (float,float,float)\n",
    "def get_ret_vol_sr(weights,portefeuille):\n",
    "        weights = np.array(weights) # Array\n",
    "        ret = np.sum(portefeuille.mean() * weights) * 252 # Float\n",
    "        vol = np.sqrt(np.dot(weights.T, np.dot(portefeuille.cov() * 252, weights))) # Float\n",
    "        sr = ret/vol #Float\n",
    "        return np.array([ret,vol,sr]) # Array\n",
    "    \n",
    "# Fonction qui permet de garder les poids égaux à 1 au niveau des matrices d'allocations : \n",
    "# Input_Type : Matrice_Row : float_List (== List)\n",
    "# Output_Type : Matrice_Row (== List)\n",
    "def sort_row(row):\n",
    "    \n",
    "    for data1,data2 in zip(np.abs(row),range(len(row))):\n",
    "        if data1<= 0.001:\n",
    "            row[data2] = 0 \n",
    "            row[pd.DataFrame(row).idxmax()] = row[pd.DataFrame(row).idxmax()] + data1\n",
    "            \n",
    "    counter = np.abs(row).sum() - 1 \n",
    "    row[pd.DataFrame(row).idxmax()] = row[pd.DataFrame(row).idxmax()] - counter\n",
    "            \n",
    "    return row\n",
    "\n",
    "# Fonction d'optimisation des Portefeuilles : \n",
    "# Input_Type : DataFrame_List,Float,Int_List(== Array),Int,Float,Int\n",
    "# Output_Type : DataFrame : Matrice_ret_vol_sharp,Array_List\n",
    "def Make_Markowitz_Optimisation(Portefeuille_list,vol_max,Bounds_list,Portefeuille_lenght,max_short_trehsold,window_lenght):\n",
    "    \n",
    "    from scipy.optimize import minimize\n",
    "    \n",
    "    Weight_matrice = [] # Liste\n",
    "    ret_vol_sr_matrice = np.zeros((len(Portefeuille_list)+1,3)) # Matrice(n x 3)\n",
    "    \n",
    "    i = 0\n",
    "                                \n",
    "    for portefeuille in Portefeuille_list:\n",
    "\n",
    "        def neg_return(weights):\n",
    "            return  get_ret_vol_sr(weights,portefeuille)[0] * - 1\n",
    "        \n",
    "        # Les contraintes sont gérées de la manière suivante : \n",
    "        # Zéro est la valeur maximale tolérée pour les inégalité et c'est la valeur à obtenir pour les égalitées.\n",
    "        \n",
    "        # Contrainte sur les Poids :\n",
    "        \n",
    "        def check_sum(weights):\n",
    "            return np.sum(np.abs(weights)) - 1\n",
    "\n",
    "        # Contrainte sur la Vol : \n",
    "\n",
    "        def check_vol(weights):\n",
    "            RHS = vol_max - get_ret_vol_sr(weights, portefeuille)[1]\n",
    "            return RHS\n",
    "        \n",
    "        # Contrainte sur les Short : \n",
    "        \n",
    "        def check_max_short(weights):\n",
    "            liste = [] # Liste\n",
    "            for value in weights:\n",
    "                if value<=0:\n",
    "                    liste.append(value)\n",
    "            return max_short_trehsold  - np.sum(np.abs(liste))\n",
    "        \n",
    "        # Construction des contraintes :\n",
    "        \n",
    "        cons = ({'type': 'eq', 'fun': check_sum}, {'type': 'ineq', 'fun': check_vol},{'type': 'ineq', 'fun': check_max_short})\n",
    "\n",
    "        # Hypothèse initiale (Répartition égale) : \n",
    "    \n",
    "        init_guess = [] \n",
    "        for k in range(Portefeuille_lenght):\n",
    "            init_guess.append(1 / Portefeuille_lenght)\n",
    "            \n",
    "            # Optimisation \"SLSQP\":\n",
    "            \n",
    "        opt_results = minimize(neg_return, init_guess, bounds = Bounds_list, method='SLSQP', constraints=cons) \n",
    "        Weight_matrice.append(opt_results.x)\n",
    "        ret_vol_sr_matrice[i,:] = get_ret_vol_sr(opt_results.x,portefeuille)\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "    ret_vol_sr_matrice = pd.DataFrame(ret_vol_sr_matrice)\n",
    "    ret_vol_sr_matrice.columns = [\"Return\",\"Vol\",\"Sharp_Ratio\"]\n",
    "    \n",
    "    for k in range(len(Weight_matrice)):\n",
    "        Weight_matrice[k] = sort_row(Weight_matrice[k])\n",
    "    \n",
    "    return ret_vol_sr_matrice,Weight_matrice\n",
    "\n",
    "# Fonction de test de la matrice d'allocation : \n",
    "# Input_Type : DataFrame\n",
    "# Output_Type : String \n",
    "def test_weight_allocated(Dataframe):\n",
    "    \n",
    "    sum_list = []\n",
    "    \n",
    "    for k in range (len(Dataframe)):\n",
    "        sum_list.append(np.sum(np.abs(Dataframe[k])))\n",
    "        \n",
    "    i = 0\n",
    "    for data in sum_list:\n",
    "        if data >1 : \n",
    "            i = i + 1\n",
    "    if i > 0:\n",
    "        print(\"Allocation valide\")\n",
    "    else : \n",
    "        print(\"allocation non valide\")\n",
    "        \n",
    "# Construcion de la fonction MAR : \n",
    "# Input_Type : Matrice, Float, DataFrame\n",
    "# Output_Type : Matrice\n",
    "def get_MAR(weight_matrice,mar_value,portefeuille):\n",
    "    \n",
    "    matrice_weight = weight_matrice.copy()\n",
    "    \n",
    "    super_liste = []\n",
    "    \n",
    "    for value1,value2 in zip(matrice_weight,portefeuille):\n",
    "        \n",
    "        liste = []\n",
    "        \n",
    "        for k,ticker in zip(range(len(value1)),value2.columns):\n",
    "            liste.append((value2[ticker].mean() * value1[k]) * 252)\n",
    "            \n",
    "        super_liste.append(liste)\n",
    "        \n",
    "    super_liste = pd.DataFrame(super_liste)\n",
    "    \n",
    "    for k in range(len(super_liste)):\n",
    "        j = 0\n",
    "        \n",
    "        for value1,value2 in zip(super_liste.loc[k][1:],matrice_weight[k][1:]):\n",
    "            if value1 <= mar_value:\n",
    "                matrice_weight[k][0] = matrice_weight[k][0] + value2\n",
    "                matrice_weight[k][1:][j] = 0 \n",
    "                \n",
    "            j = j + 1\n",
    "            \n",
    "    return matrice_weight\n",
    "\n",
    "# Préparation des portefeuilles, les rends compatibles avec l'optmimiseur : \n",
    "# Input_Type : DataFrame\n",
    "# Output_Type : DataFrame\n",
    "def prepare_portefeuille_2(Portefeuille,backtest_starting_date,backtest_ending_date):\n",
    "    portefeuille = Portefeuille.copy()\n",
    "    portefeuille = portefeuille[2:]\n",
    "    portefeuille.rename(columns = {\"Unnamed: 0\" : 'Date'},inplace = True)\n",
    "\n",
    "    if \"Date\" in portefeuille.columns:\n",
    "        portefeuille.set_index(\"Date\",inplace = True)\n",
    "        \n",
    "    portefeuille = portefeuille[backtest_starting_date:backtest_ending_date]\n",
    "    return portefeuille\n",
    "\n",
    "# Recherche des dates de rebalancement, localisation des dates de fin de calcul des nouveaux poids pour chaques périodes : \n",
    "# Input_Type : DataFrame \n",
    "# Output_Type : Date_List\n",
    "def get_allocations_dates(DataFrame) : \n",
    "    \n",
    "    liste_ = []\n",
    "    \n",
    "    for value in DataFrame:\n",
    "        liste_.append(value.index[-1])\n",
    "        \n",
    "    return liste_\n",
    "\n",
    "# Fonction d'écriture du noms de la matrice d'allocation :\n",
    "# Input_Type : Matrice,Int,Float\n",
    "# Output_Type : String\n",
    "def get_weight_name(matrice,lenght,mar_value):\n",
    "    return  TODAY + \"_\" + matrice + \" {}\".format(lenght) + ' MAR ' + \" {}\".format(mar_value) + \".xlsx\"\n",
    "\n",
    "# Fontion de produit cumulatif : \n",
    "# Input_Type : Int_List\n",
    "# Output_Type : Float\n",
    "def produit(liste):\n",
    "    _produit = 1\n",
    "    for i in liste:\n",
    "        _produit = _produit * (1 + i)\n",
    "    return _produit\n",
    "\n",
    "# Fonction pour récupérer le Ratio de Sharp annuel moyen :\n",
    "# Input_Type : Matrice \n",
    "# Outpu_Type : Float\n",
    "def get_stats(matrice): \n",
    "    return round(matrice[\"Sharp_Ratio\"].mean(),2)\n",
    "\n",
    "# Cette fonction prends en input un portefeuille et renvoie le taux Eonia capitalisé en daily :\n",
    "# Input_Type : DataFrame\n",
    "# Output_Type : Float_List\n",
    "def Get_Eonia_Rate(portefeuille):\n",
    "    \n",
    "    portefeuille_for_Eonia = portefeuille.copy()\n",
    "    portefeuille_for_Eonia.reset_index(inplace = True)\n",
    "    portefeuille_for_Eonia = portefeuille_for_Eonia[['Date','EONIA Index']]\n",
    "    portefeuille_for_Eonia.loc[:,('Days_count')] = portefeuille_for_Eonia.loc[:,('Date')].diff().dt.days\n",
    "    portefeuille_for_Eonia.loc[0,('Days_count')] = 0  \n",
    "    \n",
    "    return_list = [] \n",
    "    Eonia_capitalisation = [] \n",
    "    return_list.append(portefeuille_for_Eonia[\"EONIA Index\"][0])\n",
    "    \n",
    "    for j in range (1,len(portefeuille_for_Eonia)):\n",
    "        return_list.append(((portefeuille_for_Eonia.loc[j,('EONIA Index')]/100) * portefeuille_for_Eonia.loc[j,('Days_count')]) /365)\n",
    "        Eonia_capitalisation.append(produit(return_list))\n",
    "        \n",
    "    return (Eonia_capitalisation)\n",
    "\n",
    "# Cette fonction prends une liste de dataFrame et renvoie une liste de taux correspondants à chacuns d'entre eux :\n",
    "# Input_Type : DataFrame_List \n",
    "# Output_Type : Float_List_List\n",
    "def Get_Eonia_Rate_for_Sharp(portefeuille_list):\n",
    "    Eonia_Rate = []\n",
    "\n",
    "    for portefeuille in portefeuille_list:\n",
    "    \n",
    "        portefeuille_for_Eonia = portefeuille.copy()\n",
    "        portefeuille_for_Eonia.reset_index(inplace = True)\n",
    "        portefeuille_for_Eonia = portefeuille_for_Eonia[['Date','EONIA Index']]\n",
    "        portefeuille_for_Eonia.loc[:,('Days_count')] = portefeuille_for_Eonia.loc[:,('Date')].diff().dt.days\n",
    "        portefeuille_for_Eonia.loc[0,('Days_count')] = 0  \n",
    "        \n",
    "        Total_capitalisation = []\n",
    "        return_list = [] \n",
    "        Eonia_capitalisation = [] \n",
    "    \n",
    "        for j in range (len(portefeuille_for_Eonia)):\n",
    "            return_list.append(((portefeuille_for_Eonia.loc[j,('EONIA Index')]/100) * portefeuille_for_Eonia.loc[j,('Days_count')]) /365)\n",
    "            Eonia_capitalisation.append(produit(return_list))\n",
    "       \n",
    "        Total_capitalisation.append(Eonia_capitalisation)\n",
    "        Eonia_Rate.append((Total_capitalisation[0][-1]/Total_capitalisation[0][0])**((365/len(portefeuille_for_Eonia))-1) - 1)\n",
    "        \n",
    "    return (Eonia_Rate)\n",
    "\n",
    "# Obtention des equity_curve de chacuns des portefeuilles :\n",
    "# Input_Type : DataFrame_List,DataFrame,Matrice,String_List,int\n",
    "# Output_Type : Float_List \n",
    "def get_valorisation(Portefeuille_list,Portefeuille_before_filled,weight_matrice,Ticker_list,window_lenght):\n",
    "    \n",
    "    l = 0 \n",
    "    portefeuille_list = []\n",
    "    Index_List_Filtered_flat = Ticker_list[1:]\n",
    "    # matrice des parts Index : \n",
    "    matrice_list_parts = np.zeros((len(weight_matrice),len(Index_List_Filtered_flat)))\n",
    "    # initialisation de la liste de parts EONIA : \n",
    "    matrice_list_parts_Eonia = np.zeros((len(weight_matrice),1))\n",
    "    # Valorisation Eonia : \n",
    "    Amount = []\n",
    "    Amount.append(10000)\n",
    "\n",
    "    # utilisation de cette liste pour valorisation Eonia sur portefeuille  : \n",
    "    # préparation du portefeuille : \n",
    "    # Utiliser la capitalisation Eonia calculée plus haut : \n",
    "\n",
    "    for (portefeuille,k) in zip (Portefeuille_list, range(len(weight_matrice))):\n",
    "        matrice_list_parts_Eonia[k] = Amount[k] * np.abs(weight_matrice.iloc[k][0])\n",
    "        portefeuille_for_Eonia = portefeuille.copy()\n",
    "        portefeuille_for_Eonia.reset_index(inplace = True)\n",
    "        portefeuille_for_Eonia = portefeuille_for_Eonia[['Date','EONIA Index']]\n",
    "        portefeuille_for_Eonia.loc[:,('Days_count')] = portefeuille_for_Eonia.loc[:,('Date')].diff().dt.days\n",
    "        portefeuille_for_Eonia.loc[0,('Days_count')] = 0  \n",
    "        \n",
    "        # maintenant que le portefeuille est prèt : calcul de la valorisation : \n",
    "\n",
    "        Total_capitalisation = [] \n",
    "        return_list = [] \n",
    "        Eonia_capitalisation = [] \n",
    "        Eonia_capitalisation.append(matrice_list_parts_Eonia[k])\n",
    "    \n",
    "        for j in range (len(portefeuille_for_Eonia) - 1):\n",
    "            return_list.append(((portefeuille_for_Eonia.loc[j,('EONIA Index')]/100) * portefeuille_for_Eonia.loc[j,('Days_count')]) /360)\n",
    "            Eonia_capitalisation.append(produit(return_list) * matrice_list_parts_Eonia[k])\n",
    "    \n",
    "        Total_capitalisation.append(Eonia_capitalisation)\n",
    "    \n",
    "    \n",
    "        # Création du portefeuille de valorisation : \n",
    "    \n",
    "        portefeuille_final = pd.DataFrame(Total_capitalisation)\n",
    "        portefeuille_final = portefeuille_final.T\n",
    "        portefeuille_final.columns = [\"Eonia Capitalisé\"]\n",
    "        portefeuille_final.set_index(portefeuille_for_Eonia.Date,inplace = True)\n",
    "    \n",
    "    \n",
    "        # On passe à la valorisation du reste du portefeuille et création de la liste de portefeuille valorisés : \n",
    "\n",
    "        Nombre_de_parts = []\n",
    "\n",
    "        for weight,ticker in zip(weight_matrice.iloc[k][1:],Index_List_Filtered_flat):\n",
    "                Nombre_de_parts.append((Amount[k] * weight) / Portefeuille_before_filled[ticker][l]) # Gérer deux listes: \n",
    "                \n",
    "        matrice_list_parts[k,:] = Nombre_de_parts\n",
    "    \n",
    "        l = l + window_lenght\n",
    "    \n",
    "        portefeuille_for_valorisation = portefeuille.copy()\n",
    "        portefeuille_for_valorisation.drop(columns = [\"EONIA Index\"], inplace = True)\n",
    "        portefeuille_for_valorisation = portefeuille_for_valorisation * matrice_list_parts[k,:]\n",
    "        portefeuille_final = pd.concat([portefeuille_final,portefeuille_for_valorisation],axis = 1)\n",
    "        \n",
    "        portefeuille_final[\"Capitalisation\"] = portefeuille_final.sum(axis = 1)\n",
    "        Amount.append(portefeuille_final[\"Capitalisation\"][-1])\n",
    "        portefeuille_list.append(portefeuille_final)\n",
    "        matrice_list_parts_Eonia[k] = Amount[k] * np.abs(weight_matrice.iloc[k][0])\n",
    "    \n",
    "    # On cherche maintenant l'equity curve du portefeuille G : \n",
    "    equity_list = []\n",
    "    for portefeuille in portefeuille_list:\n",
    "        for i in portefeuille[\"Capitalisation\"]:\n",
    "            equity_list.append(i)\n",
    "        \n",
    "    return equity_list\n",
    "\n",
    "# Fonction de calcul de return : \n",
    "# Input_Type : Float_List\n",
    "# Outut_Type : Float\n",
    "def get_return(equity_curve):\n",
    "    return (equity_curve.iloc[-1]/equity_curve.iloc[0] - 1) * 100\n",
    "\n",
    "# Fonction qui permet de créer un differentiel sous_jacents/allocation : \n",
    "# Input_type : DataFrame_List,Float_List,Float_List (Double)\n",
    "# Output_Type : Float_List \n",
    "# Fonction a foutre en base 100 pour rendement relatif : \n",
    "def get_data_for_differentiel(ouput,equity_curve,Bound_list):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    Output = pd.concat(ouput[3]) # Output[3] == Portefeuille_List \n",
    "    liste = []\n",
    "    for value in Bound_list:\n",
    "        liste.append(value[1])\n",
    "        \n",
    "    Output = Output * liste\n",
    "    Output = scaler.fit_transform(Output)\n",
    "    Output = pd.DataFrame(Output).sum(axis=1)\n",
    "    Output.index = equity_curve.index\n",
    "    \n",
    "    return Output\n",
    "\n",
    "# Fonction qui permet de caller en annuel une durée : \n",
    "# Input_Type : Date,Date\n",
    "# Output_Type : Float\n",
    "def get_yearly_duration(Starting_Date,Ending_Date,window_backtest):\n",
    "    \n",
    "    start = Starting_Date.date()\n",
    "    end = Ending_Date.date()\n",
    "    output = np.busday_count(start,end) - window_backtest\n",
    "    \n",
    "    return round(output/261,3) \n",
    "\n",
    "# Fonction de calcul du time_to_recovery : \n",
    "# Input_Type : Float_Liste \n",
    "# Output_Type : Float\n",
    "# Idée : Faire un scan sur le drawdown et compter à partir d'une perte supérieure à 1.5% \n",
    "def get_time_to_recovery(drawdown_curve):\n",
    "    \n",
    "    liste = [] \n",
    "    nombre = 0 \n",
    "    \n",
    "    drawdown_curve[\"compteur\"] = drawdown_curve[drawdown_curve.columns[0]]\n",
    "    \n",
    "    for k in range (len(drawdown_curve)):\n",
    "        if drawdown_curve[drawdown_curve.columns[0]][k]*100<=-1.5:\n",
    "            drawdown_curve[\"compteur\"][k] = 1\n",
    "            \n",
    "        else : \n",
    "             drawdown_curve[\"compteur\"][k] = 0\n",
    "            \n",
    "    for k in range (len(drawdown_curve[\"compteur\"])-1):\n",
    "        if drawdown_curve[\"compteur\"][k] == 1 and drawdown_curve[\"compteur\"][k+1] == 1:\n",
    "            nombre+=1\n",
    "            \n",
    "        if drawdown_curve[\"compteur\"][k] == 1 and drawdown_curve[\"compteur\"][k+1] == 0:\n",
    "            nombre = 0\n",
    "            \n",
    "        liste.append(nombre)\n",
    "        \n",
    "    liste = pd.DataFrame(liste)\n",
    "    drawdown_curve.drop(columns = \"compteur\",inplace = True)\n",
    "    \n",
    "    return round(liste.max()/252,2)\n",
    "\n",
    "# Fonction de calcul des statistiques réalisées: \n",
    "# Input_Type : Matrice, DataFrame\n",
    "# Ouput_Type : DataFrame\n",
    "def get_realized_ret_vol_sr(weight_matrice,portefeuilles):\n",
    "    weight_matrice = weight_matrice.iloc[:-1]\n",
    "    ret_vol_sr_matrice = np.zeros((len(portefeuilles),3))\n",
    "    i = 0\n",
    "    for k in range (len(weight_matrice)):\n",
    "        \n",
    "        ret = np.sum(pd.DataFrame(portefeuilles[k]).diff().mean() * weight_matrice.iloc[k]) * 252\n",
    "        vol = np.sqrt(np.dot(weight_matrice.iloc[k].T, np.dot(pd.DataFrame(portefeuilles[k]).diff().cov() * 252, weight_matrice.iloc[k])))\n",
    "        sr = ret/vol\n",
    "        ret_vol_sr_matrice[i:] = [ret,vol,sr]\n",
    "        i = i+1\n",
    "        \n",
    "    return pd.DataFrame(ret_vol_sr_matrice)\n",
    "\n",
    "# Calcul du DD : \n",
    "# Input_Type : Float_List\n",
    "# Output_Type : Float_List\n",
    "def DD(Equity):\n",
    "    previous_peaks = Equity.cummax()\n",
    "    drawdown = (Equity-previous_peaks) / previous_peaks\n",
    "    return drawdown \n",
    "\n",
    "# Calcul du Max_DD : \n",
    "# Input_Type : Float_List\n",
    "# Output_Type : Float\n",
    "def Max_DD(equity):\n",
    "    return round(DD(equity).min()*100)\n",
    "\n",
    "# Calcul du ratio de Sortino : \n",
    "# Définition de la fonction de calcul du ratio de sortino : \n",
    "# Input_Type : Float_List,Float\n",
    "# Output_Type : Float\n",
    "# Ré écrire la fonction pour fitter avec window_lenght : \n",
    "def Sortino_Ratio(real_return,Expected_Return):\n",
    "    \n",
    "    start_index = 0\n",
    "    end_index = 12\n",
    "    annual_duration = 12\n",
    "    real_return_monthly_annually = []\n",
    "    mean_return = np.mean(real_return)\n",
    "    \n",
    "    for k in range (int(len(real_return)/12)):\n",
    "        real_return_monthly_annually.append(real_return[start_index:end_index])\n",
    "        start_index = start_index + annual_duration\n",
    "        end_index = end_index + annual_duration \n",
    "    \n",
    "    return_annual = []\n",
    "    for année in real_return_monthly_annually:\n",
    "        return_annual.append(année.mean())\n",
    "    \n",
    "    real_return_monthly_annually_mean = []\n",
    "    for année in real_return_monthly_annually:\n",
    "        real_return_monthly_annually_mean.append(année.mean())   \n",
    "    real_return_monthly_annually_mean = pd.DataFrame(real_return_monthly_annually_mean)\n",
    "    \n",
    "    list_for_Sortino = []\n",
    "    for mean in real_return_monthly_annually_mean[0]:\n",
    "        if mean <= 0.05:\n",
    "            list_for_Sortino.append(mean)   \n",
    "        \n",
    "    list_Sortino = []\n",
    "    for element in list_for_Sortino:\n",
    "        element_ = (Expected_Return - element)**2\n",
    "        list_Sortino.append(element_)\n",
    "        \n",
    "    sigma_sortino = np.sqrt(np.sum(list_Sortino)/len(real_return_monthly_annually_mean))\n",
    "    Ratio_Sortino = (mean_return - Expected_Return)/sigma_sortino\n",
    "    \n",
    "    return (round(Ratio_Sortino,2))\n",
    "\n",
    "# Calcul du ratio de Calmar : \n",
    "# Input_Type : Float,Float\n",
    "# Output_Type : Float\n",
    "def Calmar_ratio(real_return,max_DD):\n",
    "    return round(real_return/max_DD,2)\n",
    "\n",
    "# Calcul du return de la stratégie : \n",
    "# Input_Type : Float_List\n",
    "# Output_Type : Float\n",
    "def get_strategy_return(equity_curve):\n",
    "        return round(equity_curve.iloc[-1]/equity_curve.iloc[0],1)\n",
    "    \n",
    "# Calcul du return annualisé de la stratégie : \n",
    "# Input_Type : Float,Float\n",
    "# Output_Type : Float    \n",
    "def Get_Annualized_Return(Return,duration):\n",
    "    return round((round(Return,2)**(1/duration)-1)*100,2)   \n",
    "\n",
    "# Calcul du return de la stratégie : \n",
    "# Input_Type : DataFrame_List, Matrice_List\n",
    "# Output_Type : Date_Indexed_DataFrame\n",
    "def get_realized_returns(output,weight_matrice):\n",
    "    liste = [] \n",
    "    weight_matrice.columns = output[3][0].columns\n",
    "\n",
    "    for value,k in zip (output[3],range(len(output[3]))):\n",
    "        liste.append(value*weight_matrice[:-1].iloc[k])\n",
    "        \n",
    "    super_return_list = []\n",
    "    for value,k in zip(liste,range(len(output[3]))):\n",
    "        return_liste = []\n",
    "        \n",
    "        for column in value.columns:\n",
    "            return_liste.append(round(((value[column][-1]/value[column][0])-1)*100,3))\n",
    "            \n",
    "        return_liste = return_liste[1:] \n",
    "        return_liste = pd.DataFrame(return_liste).replace(np.nan, 0)\n",
    "        return_liste = round(return_liste * pd.DataFrame(weight_matrice[:-1].iloc[k][1:].values),3)\n",
    "        super_return_list.append(return_liste)\n",
    "        \n",
    "    super_return_list = pd.concat(super_return_list,axis = 1).T \n",
    "    super_return_list = pd.DataFrame(super_return_list)\n",
    "    super_return_list.index = weight_matrice.index[:-1]\n",
    "    super_return_list.columns = weight_matrice.columns[1:]\n",
    "    \n",
    "    return super_return_list\n",
    "\n",
    "# Calcul du return des sous jacents de la stratégie : \n",
    "# Input_Type : Matrice_Row\n",
    "# Output_Type : Int_Array\n",
    "def set_to_zero(liste_):\n",
    "    liste = []\n",
    "    for value in liste_:\n",
    "        if value !=0:\n",
    "            liste.append(1)\n",
    "        else:\n",
    "            liste.append(0)\n",
    "    return liste \n",
    "\n",
    "# Calcul du return des sous jacents de la stratégie : Poids fixés à un si non nuls\n",
    "# Input_Type : DataFrame_List, Matrice_List\n",
    "# Output_Type : Date_Indexed_DataFrame\n",
    "def get_returns(ouput,weight_matrice):\n",
    "    \n",
    "    liste = [] \n",
    "    for value in (ouput[3]):\n",
    "        liste.append(value)\n",
    "        \n",
    "    super_return_list = []\n",
    "    for value,k in zip(liste,range(len(ouput[3]))):\n",
    "        return_liste = []\n",
    "        \n",
    "        for column in value.columns:\n",
    "            return_liste.append(round(((value[column][-1]/value[column][0])-1)*100,3))\n",
    "            \n",
    "        for data in weight_matrice[:-1].iloc[k][1:]:\n",
    "            if data !=0:\n",
    "                data=1\n",
    "                \n",
    "        return_liste = return_liste[1:]\n",
    "        return_liste = pd.DataFrame(return_liste).replace(np.nan, 0)\n",
    "        return_liste = round(return_liste * pd.DataFrame(set_to_zero(weight_matrice[:-1].iloc[k][1:])),3)\n",
    "        super_return_list.append(return_liste)\n",
    "        \n",
    "    super_return_list = pd.concat(super_return_list,axis = 1).T \n",
    "    super_return_list = pd.DataFrame(super_return_list)\n",
    "    super_return_list.index = weight_matrice.index[:-1]\n",
    "    super_return_list.columns = weight_matrice.columns[1:]\n",
    "    \n",
    "    return super_return_list\n",
    "\n",
    "def progress_bar(progress,total):\n",
    "    \n",
    "    percent = 100 * (progress/float(total))\n",
    "    bar = '█' * int(percent) + '-' * (100 - int(percent))\n",
    "    print(f\"\\r|{bar}| {percent:.2f}%\", end = \"\\r\")\n",
    "\n",
    "\n",
    "# Fonction d'optimisation des portefeuilles, regroupe l'ensemble des fonctions définies jusqu'ici : \n",
    "# Output : Ensemble des graphes regroupants les résultats.\n",
    "def optimize(window_for_backtest,MAR_value):\n",
    "    import datetime\n",
    "    \n",
    "    if MAR_value == 0 and window_for_backtest != 0:\n",
    "        print(\"Set de paramêtres incompatibles, veuillez recommencer\")\n",
    "        \n",
    "        \n",
    "    Noms_Statistiques = []\n",
    "    Noms_Drawdowns = []\n",
    "    Noms_Equity_Curves = []\n",
    "    Table_de_correspondance = []\n",
    "    \n",
    "    k = 0 \n",
    "    \n",
    "    for (portefeuille,portefeuille_2) in zip (directory_list,portefeuille_name_list):\n",
    "        \n",
    "        wb = load_workbook(directory_path + portefeuille_2)\n",
    "        Portefeuille = pd.read_excel(portefeuille)\n",
    "        # Lecture des fichiers Excel : \n",
    "        \n",
    "        # Get Basis Curency :\n",
    "        coord = next(wb.defined_names[\"_BasisCcy\"].destinations)\n",
    "        basis = wb[coord[0]][coord[1]].value\n",
    "\n",
    "        # Listes des Tickers :\n",
    "        ws, range_= next(wb.defined_names[\"Ticker_list\"].destinations)\n",
    "        Ticker_List = [[cell.value for cell in row] for row in wb[ws][range_]]\n",
    "\n",
    "        Ticker_List_flat = []\n",
    "        for i in Ticker_List:\n",
    "            for j in i:\n",
    "                if j != None:\n",
    "                    Ticker_List_flat.append(j)\n",
    "\n",
    "        # Récupération du format pour les Back-tests :\n",
    "        coord = next(wb.defined_names[\"window_lenght\"].destinations)\n",
    "        window_lenght = wb[coord[0]][coord[1]].value\n",
    "            \n",
    "        # Listes des Asset_Bounds :\n",
    "        ws_bound, range_bound= next(wb.defined_names[\"Min_Max_list\"].destinations)\n",
    "        Bound_List = [[cell.value for cell in row] for row in wb[ws_bound][range_bound]]\n",
    "        \n",
    "        Bound_List_filtered = []\n",
    "        \n",
    "        for value in Bound_List:\n",
    "            if value != [None,None]:\n",
    "                Bound_List_filtered.append(value)\n",
    "\n",
    "        \"\"\"# Starting Date : \n",
    "        coord = next(wb.defined_names[\"Ending_Date\"].destinations)\n",
    "        Ending_Date = wb[coord[0]][coord[1]].value\n",
    "        \n",
    "        # Ending Date : \n",
    "        coord = next(wb.defined_names[\"Starting_Date\"].destinations)\n",
    "        Starting_Date = wb[coord[0]][coord[1]].value\"\"\"\n",
    "        \n",
    "        # Vol Max : \n",
    "        coord = next(wb.defined_names[\"Vol_Max\"].destinations)\n",
    "        Vol_MAX = wb[coord[0]][coord[1]].value\n",
    "\n",
    "        # Backtest_starting_date : \n",
    "        backtest_starting_date = datetime.datetime(année_début, mois_début, jour_début)\n",
    "        backtest_starting_date = backtest_starting_date + BDay(1)\n",
    "        backtest_starting_date = datetime.datetime(int(str(backtest_starting_date)[:4]), int(str(backtest_starting_date)[5:7]), int(str(backtest_starting_date)[8:10]))\n",
    "\n",
    "        # Backtest_ending_date : \n",
    "        backtest_ending_date = datetime.datetime(année_fin,mois_fin,jour_fin)\n",
    "        backtest_ending_date = backtest_ending_date + BDay(1)\n",
    "        backtest_ending_date = datetime.datetime(int(str(backtest_ending_date)[:4]), int(str(backtest_ending_date)[5:7]), int(str(backtest_ending_date)[8:10]))\n",
    "        \n",
    "        Portefeuille = prepare_portefeuille_2(Portefeuille,backtest_starting_date,backtest_ending_date)\n",
    "        Portefeuille_lenght = len(Portefeuille.columns)\n",
    "\n",
    "        # MAR : Si le paramêtre MAR est fixé à 0 : Alors optimisation selons les deux MAR spécifiés sur les fichiers Excel.\n",
    "        if MAR_value == 0 and window_for_backtest == 0:\n",
    "                        \n",
    "            coord = next(wb.defined_names[\"window_backtest_93\"].destinations)\n",
    "            window_backtest_93 = wb[coord[0]][coord[1]].value\n",
    "            \n",
    "            coord = next(wb.defined_names[\"window_backtest_63\"].destinations)\n",
    "            window_backtest_63 = wb[coord[0]][coord[1]].value\n",
    "            \n",
    "            window_backtest_list = [window_backtest_63,window_backtest_93]\n",
    "            \n",
    "            coord = next(wb.defined_names[\"MAR_63\"].destinations)\n",
    "            MAR_63 = wb[coord[0]][coord[1]].value       \n",
    "            \n",
    "            coord = next(wb.defined_names[\"MAR_93\"].destinations)\n",
    "            MAR_93 = wb[coord[0]][coord[1]].value \n",
    "                    \n",
    "            Liste_MAR = [MAR_63,MAR_93]\n",
    "            \n",
    "            for (MAR,j) in zip(Liste_MAR,range(len(Liste_MAR))):\n",
    "                \n",
    "                window_backtest = window_backtest_list[j]\n",
    "\n",
    "                Output =  prepare_portefeuille(Portefeuille,window_backtest,window_lenght,backtest_starting_date,backtest_ending_date)         \n",
    "                Log_return_portefeuille_liste = Output[-1]\n",
    "            \n",
    "\n",
    "                ret_vol_sr_matrice,Weight_matrice = Make_Markowitz_Optimisation(Log_return_portefeuille_liste,Vol_MAX,Bound_List_filtered,Portefeuille_lenght,max_short_trehsold,window_lenght)\n",
    "\n",
    "                Weight_matrice = get_MAR(Weight_matrice,MAR,Log_return_portefeuille_liste)\n",
    "                Weight_matrice = pd.DataFrame(Weight_matrice)\n",
    "                Weight_matrice.columns = Ticker_List_flat\n",
    "                Weight_matrice.index = get_allocations_dates(Log_return_portefeuille_liste)\n",
    "\n",
    "                realized_returns = get_realized_returns(Output,Weight_matrice)\n",
    "\n",
    "                realized_returns.to_excel(Liste_for_database_mngt[k] + \"/Realized returns\" + '/' + '{}'.format(TODAY)  + \"{}\".format(portefeuille[-16:-5]) +  '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' +'{}'.format(MAR) + '.xlsx')\n",
    "                plt.figure(figsize = (25,13))\n",
    "                plt.plot(realized_returns,label = realized_returns.columns)\n",
    "                plt.legend(loc = 0)\n",
    "                plt.title('{}'.format(TODAY) + \"{}\".format(portefeuille) + ' Realized returns' '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' +'{}'.format(MAR))\n",
    "                plt.savefig(Liste_for_database_mngt[k] + \"/Realized returns\" + '/'  + '{}'.format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + ' Realized returns_' + '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' + '{}'.format(MAR) + '.png')\n",
    "\n",
    "                returns = get_returns(Output,Weight_matrice)\n",
    "\n",
    "                plt.figure(figsize = (25,13))\n",
    "                plt.plot(returns,label = returns.columns)\n",
    "                plt.legend(loc = 0)\n",
    "                plt.title('{}'.format(TODAY) + \"{}\".format(portefeuille) + ' Absolute returns' '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' +'{}'.format(MAR))\n",
    "                plt.savefig(Liste_for_database_mngt[k] + \"/Absolute returns\" + '/'  + '{}'.format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + ' Absolute returns' + ' {}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' + '{}'.format(MAR) + '.png')\n",
    "\n",
    "                plt.figure(figsize = (25,13))\n",
    "                plt.stackplot(Weight_matrice.index,[Weight_matrice[Weight_matrice.columns[i]] for i in range(1, len(Weight_matrice.columns))],Weight_matrice[Weight_matrice.columns[0]],labels = Weight_matrice.columns[1:],colors = color_liste[-len(Weight_matrice.columns):])\n",
    "                plt.legend(loc=2)\n",
    "                plt.title(\"{}\".format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + \"_\" +   \"Allocation\" + \"_\" + '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' +'{}'.format(MAR))\n",
    "                plt.savefig(Liste_for_database_mngt[k] + \"/Profils allocation\" + '/'  +\"{}\".format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + \" Profil Allocation\" + \"_\" + '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght) + '_' + 'MAR' +'{}'.format(MAR) + '.png')\n",
    "\n",
    "                Weight_matrice.to_excel(Liste_for_database_mngt[k] + \"/Weight matrices\" + '/'  + \"{} \".format(TODAY) + \"{} \".format(portefeuille[-16:-5]) + get_weight_name(\"Weight_matrice\",window_backtest,MAR))\n",
    "\n",
    "                # Construction des Equity_curve : \n",
    "                equity_list = get_valorisation(Output[3],Output[2],Weight_matrice,Ticker_List_flat,window_lenght)\n",
    "                equity_list = pd.DataFrame(equity_list)\n",
    "                equity_list.set_index(Output[2].index, inplace=True)\n",
    "\n",
    "                Real_Return = get_return(equity_list)[0]\n",
    "\n",
    "                # Plotting des Equity_curve :\n",
    "                plt.figure(figsize = (25,13))\n",
    "                plt.plot(equity_list,label = \"Equity_Curve\" + '{}'.format(portefeuille[-16:-5]))\n",
    "                plt.legend()\n",
    "                plt.title(\"Equity_curve du Portefeuille\")\n",
    "                equity_list.to_csv(Liste_for_database_mngt[k] + \"/Equity Curves\" + '/'  +'{}'.format(TODAY) + \" {}\".format(portefeuille[-16:-5]) +  \" equity Curve\"+ ' {}'.format(window_backtest) +' MAR' + ' {}'.format(MAR) +\".csv\")\n",
    "\n",
    "                # Calcul de la performance absolu des lignes du portefeuilles pour pouvoir comparer avec l'equity curve obtenue : \n",
    "                perf = get_data_for_differentiel(Output,equity_list,Bound_List_filtered)\n",
    "                fig, ax1 = plt.subplots(figsize = (25,13))\n",
    "                ax1.plot(perf,color = 'red')\n",
    "                ax2 = ax1.twinx()\n",
    "                ax2.plot(equity_list,label = \"Equity Curve\")\n",
    "                plt.title(\"{}\".format(TODAY) + \"Performance absolue des lignes VS Equity Curve\" + \" Markowitz classique\" + \"{}\".format(MAR))\n",
    "                plt.legend()\n",
    "                plt.savefig(Liste_for_database_mngt[k] + \"/Performances VS Equity Curves\" + '/'  +\"{}\".format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + '{}'.format(window_backtest) + \" Performance absolue des lignes VS Equity Curve\" + \"{}\".format(MAR) + \".png\")\n",
    "\n",
    "                 # Calcul et affichage du Max Drawdown : \n",
    "                previous_peaks = equity_list.cummax()\n",
    "                drawdown =  (equity_list-previous_peaks) / previous_peaks\n",
    "\n",
    "                plt.figure(figsize = (25,13))\n",
    "                plt.plot(drawdown,label = \"Drawdown\")\n",
    "                plt.legend()\n",
    "                plt.title('Drawdown du portefeuille')\n",
    "                plt.savefig(Liste_for_database_mngt[k] + \"/Drawdowns\" + '/' +'{}'.format(TODAY) + \" Drawdown du Portefeuille\" + \"{}\".format(portefeuille[-16:-5]) + '{}'.format(window_backtest) +'MAR' +'{}'.format(MAR) +'.png')\n",
    "                drawdown.to_csv(Liste_for_database_mngt[k] + \"/Drawdowns csv\" + '/' +'{}'.format(TODAY) + \" Drawdown du Portefeuille\" + \" {}\".format(portefeuille[-16:-5]) + ' {}'.format(window_backtest) +' MAR' +' {}'.format(MAR) +'.csv')\n",
    "\n",
    "                Real_Return = get_return(equity_list)[0]\n",
    "                total_return = round(get_strategy_return(equity_list)[0],3)\n",
    "                duration  = get_yearly_duration(backtest_starting_date,backtest_ending_date,window_backtest)\n",
    "\n",
    "                 # Création du Tableaux regroupant les statistiques : \n",
    "                Annualized_return = Get_Annualized_Return(total_return,duration)\n",
    "                MaX_DD = Max_DD(equity_list)[0]\n",
    "                returns = (equity_list.iloc[-1]/equity_list.iloc[0]) -1 \n",
    "                Calmar_Ratio = Annualized_return/MaX_DD\n",
    "                Mean_Annualized_vol = get_realized_ret_vol_sr(Weight_matrice,Output[3])[1].mean()\n",
    "                Mean_Annualized_return = get_realized_ret_vol_sr(Weight_matrice,Output[3])[0].mean()\n",
    "                Mean_Sharp_ratio = Mean_Annualized_return/Mean_Annualized_vol\n",
    "                Annualized_time_to_recovery = get_time_to_recovery(drawdown)[0]\n",
    "                stats_liste = [(total_return-1) * 100 ,Mean_Annualized_return,Mean_Annualized_vol,MaX_DD,Calmar_Ratio,Mean_Sharp_ratio,Annualized_time_to_recovery]\n",
    "\n",
    "                liste = []\n",
    "                for value in stats_liste:\n",
    "                    liste.append(round(value,3))\n",
    "\n",
    "                liste = pd.DataFrame(stats_liste).T\n",
    "                liste.columns = [\"total_return : Start to Date %\",\"Mean Annualizedreturn\",\"Mean Annualized Vol\",\"MaX Drawdown\",\"Calmar Ratio\",\"Sharp Ratio\",\"Annualized time to recovery\"]\n",
    "                infos = [\"Statistiques de la stratégie\"]\n",
    "                liste.index = infos\n",
    "                liste.to_excel(Liste_for_database_mngt[k] + \"/Statistiques\" + '/'  + '{}'.format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + ' Statistiques_Portefeuilles' +' {}'.format(window_backtest) + ' {}'.format(window_lenght)  +'{}'.format(MAR) + '.xlsx')\n",
    "                \n",
    "                progress_bar(k,len(Liste_for_database_mngt))\n",
    "\n",
    "                Noms_Statistiques.append(Liste_for_database_mngt[k] + \"/Statistiques\" + '/'  + '{}'.format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + ' Statistiques_Portefeuilles' +' {}'.format(window_backtest) + ' {}'.format(window_lenght)  +'{}'.format(MAR) + '.xlsx')\n",
    "                Noms_Drawdowns.append(Liste_for_database_mngt[k] + \"/Drawdowns csv\" + '/' +'{}'.format(TODAY) + \" Drawdown du Portefeuille\" + \"{}\".format(portefeuille[-16:-5]) + '{}'.format(window_backtest) +'MAR' +'{}'.format(MAR) +'.csv')\n",
    "                Noms_Equity_Curves.append(Liste_for_database_mngt[k] + \"/Equity Curves\" + '/'  +'{}'.format(TODAY) + \"{}\".format(portefeuille[-16:-5]) +  \" equity Curve\"+ '{}'.format(window_backtest) +'MAR' + '{}'.format(MAR) + \".csv\")\n",
    "                k = k + 1                       \n",
    "            \n",
    "            Table_de_correspondance = Noms_Statistiques\n",
    "            Table_de_correspondance = pd.DataFrame(Table_de_correspondance)\n",
    "            Table_de_correspondance[\"Drawdowns\"] = Noms_Drawdowns\n",
    "            Table_de_correspondance[\"Equity Curves\"] = Noms_Equity_Curves\n",
    "\n",
    "            return Table_de_correspondance\n",
    "\n",
    "        else: \n",
    "            \n",
    "            window_backtest = int(window_for_backtest)   \n",
    "            MAR = MAR_value\n",
    "        \n",
    "                \n",
    "            Output =  prepare_portefeuille(Portefeuille,window_backtest,window_lenght,backtest_starting_date,backtest_ending_date)         \n",
    "            Log_return_portefeuille_liste = Output[-1]\n",
    "            Portefeuille = prepare_portefeuille_2(Portefeuille,backtest_starting_date,backtest_ending_date)\n",
    "            Portefeuille_lenght = len(Portefeuille.columns)\n",
    "\n",
    "            ret_vol_sr_matrice,Weight_matrice = Make_Markowitz_Optimisation(Log_return_portefeuille_liste,Vol_MAX,Bound_List_filtered,Portefeuille_lenght,max_short_trehsold,window_lenght)\n",
    "\n",
    "            Weight_matrice = get_MAR(Weight_matrice,MAR,Log_return_portefeuille_liste)\n",
    "            Weight_matrice = pd.DataFrame(Weight_matrice)\n",
    "            Weight_matrice.columns = Ticker_List_flat\n",
    "            Weight_matrice.index = get_allocations_dates(Log_return_portefeuille_liste)\n",
    "\n",
    "            realized_returns = get_realized_returns(Output,Weight_matrice)\n",
    "\n",
    "            realized_returns.to_excel(Liste_for_database_mngt[k] + \"/Realized returns\" + '/' + '{}'.format(TODAY)  + \"{}\".format(portefeuille[-16:-5]) +  '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' +'{}'.format(MAR) + '.xlsx')\n",
    "            plt.figure(figsize = (25,13))\n",
    "            plt.plot(realized_returns,label = realized_returns.columns)\n",
    "            plt.legend(loc = 0)\n",
    "            plt.title('{}'.format(TODAY) + \"{}\".format(portefeuille) + ' Realized returns' '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' +'{}'.format(MAR))\n",
    "            plt.savefig(Liste_for_database_mngt[k] + \"/Realized returns\" + '/'  + '{}'.format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + ' Realized returns_' + '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' + '{}'.format(MAR) + '.png')\n",
    "\n",
    "            returns = get_returns(Output,Weight_matrice)\n",
    "\n",
    "            plt.figure(figsize = (25,13))\n",
    "            plt.plot(returns,label = returns.columns)\n",
    "            plt.legend(loc = 0)\n",
    "            plt.title('{}'.format(TODAY) + \"{}\".format(portefeuille) + ' Absolute returns' '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' +'{}'.format(MAR))\n",
    "            plt.savefig(Liste_for_database_mngt[k] + \"/Absolute returns\" + '/'  + '{}'.format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + ' Absolute returns' + ' {}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' + '{}'.format(MAR) + '.png')\n",
    "\n",
    "            plt.figure(figsize = (25,13))\n",
    "            plt.stackplot(Weight_matrice.index,[Weight_matrice[Weight_matrice.columns[i]] for i in range(1, len(Weight_matrice.columns))],Weight_matrice[Weight_matrice.columns[0]],labels = Weight_matrice.columns[1:],colors = color_liste[-len(Weight_matrice.columns):])\n",
    "            plt.legend(loc=2)\n",
    "            plt.title(\"{}\".format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + \"_\" +   \"Allocation\" + \"_\" + '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght)+ '_' + 'MAR' +'{}'.format(MAR))\n",
    "            plt.savefig(Liste_for_database_mngt[k] + \"/Profils allocation\" + '/'  +\"{}\".format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + \" Profil Allocation\" + \"_\" + '{}'.format(window_backtest) + \"_\"  + '{}'.format(window_lenght) + '_' + 'MAR' +'{}'.format(MAR) + '.png')\n",
    "\n",
    "            Weight_matrice.to_excel(Liste_for_database_mngt[k] + \"/Weight matrices\" + '/'  + \"{} \".format(TODAY) + \"{} \".format(portefeuille[-16:-5]) + get_weight_name(\"Weight_matrice\",window_backtest,MAR))\n",
    "\n",
    "            # Construction des Equity_curve : \n",
    "            equity_list = get_valorisation(Output[3],Output[2],Weight_matrice,Ticker_List_flat,window_lenght)\n",
    "            equity_list = pd.DataFrame(equity_list)\n",
    "            equity_list.set_index(Output[2].index, inplace=True)\n",
    "\n",
    "            Real_Return = get_return(equity_list)[0]\n",
    "\n",
    "            # Plotting des Equity_curve :\n",
    "            plt.figure(figsize = (25,13))\n",
    "            plt.plot(equity_list,label = \"Equity_Curve\" + '{}'.format(portefeuille[-16:-5]))\n",
    "            plt.legend()\n",
    "            plt.title(\"Equity_curve du Portefeuille\")\n",
    "            equity_list.to_csv(Liste_for_database_mngt[k] + \"/Equity Curves\" + '/'  +' {}'.format(TODAY) + \" {}\".format(portefeuille[-16:-5]) +  \" equity Curve\"+ ' {}'.format(window_backtest) +' MAR' + ' {}'.format(MAR) +\".csv\")\n",
    "\n",
    "            # Calcul de la performance absolu des lignes du portefeuilles pour pouvoir comparer avec l'equity curve obtenue : \n",
    "            perf = get_data_for_differentiel(Output,equity_list,Bound_List_filtered)\n",
    "            fig, ax1 = plt.subplots(figsize = (25,13))\n",
    "            ax1.plot(perf,color = 'red')\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(equity_list,label = \"Equity Curve\")\n",
    "            plt.title(\"{}\".format(TODAY) + \"Performance absolue des lignes VS Equity Curve\" + \" Markowitz classique\" + \"{}\".format(MAR))\n",
    "            plt.legend()\n",
    "            plt.savefig(Liste_for_database_mngt[k] + \"/Performances VS Equity Curves\" + '/'  +\"{}\".format(TODAY) + \"{}\".format(portefeuille[-16:-5]) + '{}'.format(window_backtest) + \" Performance absolue des lignes VS Equity Curve\" + \"{}\".format(MAR) + \".png\")\n",
    "\n",
    "             # Calcul et affichage du Max Drawdown : \n",
    "            previous_peaks = equity_list.cummax()\n",
    "            drawdown =  (equity_list-previous_peaks) / previous_peaks\n",
    "\n",
    "            plt.figure(figsize = (25,13))\n",
    "            plt.plot(drawdown,label = \"Drawdown\")\n",
    "            plt.legend()\n",
    "            plt.title('Drawdown du portefeuille')\n",
    "            plt.savefig(Liste_for_database_mngt[k] + \"/Drawdowns\" + '/' +'{}'.format(TODAY) + \" Drawdown du Portefeuille\" + \"{}\".format(portefeuille[-16:-5]) + '{}'.format(window_backtest) +'MAR' +'{}'.format(MAR) +'.png')\n",
    "            drawdown.to_csv(Liste_for_database_mngt[k] + \"/Drawdowns csv\" + '/' +' {}'.format(TODAY) + \" Drawdown du Portefeuille\" + \" {}\".format(portefeuille[-16:-5]) + ' {}'.format(window_backtest) +' MAR' +' {}'.format(MAR) +'.csv')\n",
    "\n",
    "            Real_Return = get_return(equity_list)[0]\n",
    "            total_return = round(get_strategy_return(equity_list)[0],3)\n",
    "            duration  = get_yearly_duration(backtest_starting_date,backtest_ending_date,window_backtest)\n",
    "\n",
    "            # Création du Tableaux regroupant les statistiques : \n",
    "            Annualized_return = Get_Annualized_Return(total_return,duration)\n",
    "            MaX_DD = Max_DD(equity_list)[0]\n",
    "            returns = (equity_list.iloc[-1]/equity_list.iloc[0]) -1 \n",
    "            Calmar_Ratio = Annualized_return/MaX_DD\n",
    "            Mean_Annualized_vol = get_realized_ret_vol_sr(Weight_matrice,Output[3])[1].mean()\n",
    "            Mean_Annualized_return = get_realized_ret_vol_sr(Weight_matrice,Output[3])[0].mean()\n",
    "            Mean_Sharp_ratio = Mean_Annualized_return/Mean_Annualized_vol\n",
    "            Annualized_time_to_recovery = get_time_to_recovery(drawdown)[0]\n",
    "            stats_liste = [(total_return-1) * 100 ,Mean_Annualized_return,Mean_Annualized_vol,MaX_DD,Calmar_Ratio,Mean_Sharp_ratio,Annualized_time_to_recovery]\n",
    "\n",
    "            liste = []\n",
    "            for value in stats_liste:\n",
    "                liste.append(round(value,3))\n",
    "\n",
    "            liste = pd.DataFrame(stats_liste).T\n",
    "            liste.columns = [\"total_return : Start to Date %\",\"Mean Annualizedreturn\",\"Mean Annualized Vol\",\"MaX Drawdown\",\"Calmar Ratio\",\"Sharp Ratio\",\"Annualized time to recovery\"]\n",
    "            infos = [\"Statistiques de la stratégie\"]\n",
    "            liste.index = infos\n",
    "            \n",
    "            liste.to_excel(Liste_for_database_mngt[k] + \"/Statistiques\" + '/'  + ' {}'.format(TODAY) + \" {}\".format(portefeuille[-16:-5]) + ' Statistiques_Portefeuilles' +' {}'.format(window_backtest) + ' {}'.format(window_lenght)  +' {}'.format(MAR) + '.xlsx')\n",
    "            progress_bar(k,len(Liste_for_database_mngt))\n",
    "\n",
    "            \n",
    "            Noms_Statistiques.append(Liste_for_database_mngt[k] + \"/Statistiques\" + '/'  + ' {}'.format(TODAY) + \" {}\".format(portefeuille[-16:-5]) + ' Statistiques_Portefeuilles' +' {}'.format(window_backtest) + ' {}'.format(window_lenght)  +' {}'.format(MAR) + '.xlsx')\n",
    "            Noms_Drawdowns.append(Liste_for_database_mngt[k] + \"/Drawdowns csv\" + '/' +' {}'.format(TODAY) + \" Drawdown du Portefeuille\" + \" {}\".format(portefeuille[-16:-5]) + ' {}'.format(window_backtest) +' MAR' +' {}'.format(MAR) +'.csv')\n",
    "            Noms_Equity_Curves.append(Liste_for_database_mngt[k] + \"/Equity Curves\" + '/'  +' {}'.format(TODAY) + \" {}\".format(portefeuille[-16:-5]) +  \" equity Curve\"+ ' {}'.format(window_backtest) +' MAR' + ' {}'.format(MAR) + \".csv\")\n",
    "            \n",
    "            k = k + 1    \n",
    "            \n",
    "        Table_de_correspondance = Noms_Statistiques\n",
    "        Table_de_correspondance = pd.DataFrame(Table_de_correspondance)\n",
    "        Table_de_correspondance[\"Drawdowns\"] = Noms_Drawdowns\n",
    "        Table_de_correspondance[\"Equity Curves\"] = Noms_Equity_Curves\n",
    "\n",
    "\n",
    "    return  Table_de_correspondance\n",
    "\n",
    "# Fonction de trie des résultats selon un critère:\n",
    "# Input : Le filtre : string, le nombre de data à afficher : int,La liste des datafram à lire DataFrame\n",
    "# Output : Liste de DataFrame trié : DataFrame_List \n",
    "def get_sorted(thing,lenght,dataframe):\n",
    "    \n",
    "    \n",
    "    liste_to_append = [] \n",
    "    value_list = []\n",
    "    dataset = pd.concat(dataframe)\n",
    "    \n",
    "    for value in dataset.loc[0].values:\n",
    "    \n",
    "        df = pd.read_excel(value)\n",
    "\n",
    "        liste_to_append.append(df)\n",
    "        value_list.append(value)\n",
    "        \n",
    "    output = pd.concat(liste_to_append)\n",
    "    output[\"Name\"] = value_list\n",
    "    output.drop(columns = [\"Unnamed: 0\"],inplace = True)\n",
    "    output.set_index(\"Name\",inplace =True)\n",
    "        \n",
    "    if thing == \"Total Return\":\n",
    "        output.sort_values(by = output.columns[0],ascending = False,inplace =True)\n",
    "\n",
    "    if thing == \"Mean Return\":\n",
    "        output.sort_values(by = output.columns[1],ascending = False,inplace =True)\n",
    "\n",
    "    if thing == \"Max Drawdown\":\n",
    "        output.sort_values(by = output.columns[3],ascending = False,inplace =True)\n",
    "\n",
    "    if thing == \"Sharp Ratio\":\n",
    "        output.sort_values(by = output.columns[5],ascending = False,inplace =True)\n",
    "\n",
    "    if thing == \"Time To Recovery\":\n",
    "        output.sort_values(by = output.columns[6],ascending = True,inplace =True)\n",
    "            \n",
    "    if thing == \"Calmar Ratio\":\n",
    "        output.sort_values(by = output.columns[4],ascending = True,inplace =True)    \n",
    "            \n",
    "    return output[:lenght]\n",
    "\n",
    "# Table de correspondance entre les tableaux contenant les statistiques et les Valeurs à dessiner :\n",
    "# Input : Liste de Noms de DataFrame Statistique,\n",
    "def get_dataframes_names(sorted_statistiques_dataframe,Final_dataframe,statistique):\n",
    "    \n",
    "    index_wanted = []\n",
    "    liste = [] \n",
    "    \n",
    "    for k in range (len(sorted_statistiques_dataframe)):\n",
    "        index_wanted.append(Final_dataframe.index[Final_dataframe[0] == sorted_statistiques_dataframe.index[k]][0])\n",
    "    \n",
    "    for index in index_wanted:\n",
    "        liste.append(Final_dataframe.loc[index][statistique])\n",
    "        \n",
    "    return liste\n",
    "\n",
    "# Fonction pour lire les fichiers dans un dossier:\n",
    "# Input : String\n",
    "def get_files_in_folder(path):\n",
    "    \n",
    "    Liste_files = []\n",
    "    \n",
    "    for files in walk (path):\n",
    "        Liste_files.extend(files)\n",
    "        \n",
    "    Liste_files = Liste_files[2]\n",
    "    \n",
    "    return Liste_files\n",
    "\n",
    "# Fonction d'obtention des multiplots:\n",
    "# Input : String : noms du dossier contenant les fichiers à dessiner\n",
    "# Output : Multiple Plots\n",
    "def get_multiple_plotting(statistique_to_filter,data_to_plot,dataframe_list,final_dataframe,lenght):\n",
    "    super_liste = []\n",
    "    for k in range (len(portefeuille_name_list)):\n",
    "        \n",
    "        liste_ = []\n",
    "        \n",
    "        for value in dataframe_list:\n",
    "        \n",
    "            liste_.append(value.loc[k])\n",
    "            \n",
    "        path =  portefeuille_name_list[k][:-5] + \"/\" +  data_to_plot + \"/\"\n",
    "        \n",
    "        sorted_statistiques_dataframe = get_sorted(statistique_to_filter,lenght,liste_)\n",
    "        \n",
    "        if data_to_plot == \"Drawdowns csv\":\n",
    "            \n",
    "            value_for_files_names_list = \"Drawdowns\"\n",
    "            \n",
    "        if data_to_plot == \"Equity Curves\":\n",
    "            \n",
    "            value_for_files_names_list = \"Equity Curves\"    \n",
    "            \n",
    "        files_names_list = get_dataframes_names(sorted_statistiques_dataframe,final_dataframe,value_for_files_names_list)\n",
    "        \n",
    "        liste = []\n",
    "        \n",
    "        for value in files_names_list:\n",
    "\n",
    "            df = pd.read_csv(value)\n",
    "            df.set_index(df.columns[0][-10:],inplace = True)\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.columns = [value[-24:]]\n",
    "            liste.append(df)\n",
    "\n",
    "        liste = pd.concat(liste,axis = 1)\n",
    "        liste.plot(colormap='gist_yarg',figsize = (20,10))\n",
    "        plt.title(portefeuille_name_list[k][:-5] + \" \" + data_to_plot + \" trié selon \"+ '{}'.format(statistique_to_filter))\n",
    "        \n",
    "        if data_to_plot == \"Equity Curves\":\n",
    "            \n",
    "            plt.savefig(portefeuille_name_list[k][:-5] + \"/Multiplots_Equity_Curves/\" + \" {}\".format(TODAY) + portefeuille_name_list[k][:-5] + \" \" + data_to_plot + \" filtre selon \"+ '{}'.format(statistique_to_filter) + \".png\")\n",
    "          \n",
    "        if data_to_plot == \"Drawdowns csv\":\n",
    "            \n",
    "            plt.savefig(portefeuille_name_list[k][:-5] + \"/Multiplots_Drawdowns/\" + \" {}\".format(TODAY) + portefeuille_name_list[k][:-5] + \" \" + data_to_plot + \" filtre selon \"+ '{}'.format(statistique_to_filter) + \".png\")\n",
    "        \n",
    "        plt.legend()\n",
    "        super_liste.append(liste) \n",
    "\n",
    "    return super_liste \n",
    "\n",
    "# Spécifier L'ensemble des paramêtres que cette fonction peut prendre et construire un pipeline qui plot tous les résultats :\n",
    "Input_list_filters = [\"Total Return\",\"Mean Return\",\"Max Drawdown\",\"Sharp Ratio\",\"Time To Recovery\",\"Calmar Ratio\"]\n",
    "Input_list_thing_to_plot = [\"Equity Curves\",\"Drawdowns csv\"]\n",
    "\n",
    "def get_all_the_multi_plottings(Input_list_filters,Input_list_thing_to_plot,number):\n",
    "    \n",
    "    liste = []\n",
    "    \n",
    "    for filtre in Input_list_filters:\n",
    "        for thing in Input_list_thing_to_plot:\n",
    "            liste.append(get_multiple_plotting(filtre,thing,dataframe_list_decile,Final_dataframe,number))\n",
    "            \n",
    "    return liste    \n",
    "\n",
    "if Choix_optimisation==1:\n",
    "    Mar_list = (-0.0150,-0.0125,-0.01,-0.0075,-0.0050,-0.0025,0.0025,0.005,0.0075,0.01,0.0125,0.0150)\n",
    "    window_backtest_list = (63,93)                                \n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    dataframe_list_decile = []                                    \n",
    "    for value in window_backtest_list:\n",
    "        for value_1 in Mar_list:\n",
    "            dataframe_list_decile.append(optimize(value,value_1))\n",
    "    Final_dataframe = pd.concat(dataframe_list_decile)\n",
    "    Final_dataframe.reset_index(inplace = True)\n",
    "    Final_dataframe.drop(columns = ['index'],inplace = True)\n",
    "    liste_dataframe_ = get_all_the_multi_plottings(Input_list_filters,Input_list_thing_to_plot,8)\n",
    "    \n",
    "if Choix_optimisation==2:\n",
    "    print(\"Veuillez Sélectionner le MAR que vous souhaitez : 1.5% == 0.015\")\n",
    "    Mar_value = input()\n",
    "    Mar_value = float(Mar_value)\n",
    "    window_backtest_list = (63,93)\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    for value in window_backtest_list:\n",
    "          optimize(value,Mar_value)\n",
    "                                         \n",
    "if Choix_optimisation==3:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    dataframe_list_decile = []\n",
    "    dataframe_list_decile.append(optimize(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5a8b2-b650-4c48-99a5-152affc22eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veuillez Sélectionner Les paramêtres que vous souhaitez afin d'obtenir une attribution de performance : \n",
      "input 1 :window_backtest_1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 2 :window_backtest_2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 3 :window_lenght_1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 4 :window_lenght_2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 5 : mar_value\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 11\n"
     ]
    }
   ],
   "source": [
    "print(\"Veuillez Sélectionner Les paramêtres que vous souhaitez afin d'obtenir une attribution de performance : \")\n",
    "print(\"input 1 :window_backtest_1\")\n",
    "window_backtest_1 = input()\n",
    "window_backtest_1 = int(window_backtest_1)\n",
    "\n",
    "print(\"input 2 :window_backtest_2\")\n",
    "window_backtest_2 = input()\n",
    "window_backtest_2 = int(window_backtest_2)\n",
    "\n",
    "print(\"input 3 :window_lenght_1\")\n",
    "window_lenght_1 = input()\n",
    "window_lenght_1 = int(window_lenght_1)\n",
    "\n",
    "print(\"input 4 :window_lenght_2\")\n",
    "window_lenght_2 = input()\n",
    "window_lenght_2 = int(window_lenght_2)\n",
    "\n",
    "print(\"input 5 : mar_value\")\n",
    "mar_value = input()\n",
    "mar_value = float(mar_value)\n",
    "#for k in range(len(Liste_for_database_mngt)):\n",
    " #   os.mkdir(Liste_for_database_mngt[k] + \"/Performances attribution\")\n",
    "    \n",
    "sub_directory_database_list = [\"/Performances attribution\"]\n",
    "sub_directory_weights = [\"/Weight matrices\"]\n",
    "\n",
    "for k in range (len(directory_list)):\n",
    "    directory_path_attributions = Liste_for_database_mngt[k] + sub_directory_database_list[0]\n",
    "\n",
    "# Fonction de calcul des attributions de performances : \n",
    "# Input : int,int,int,int,float\n",
    "# Elle renvoie 3 graphes, l'un pour le premier paramêtre le second pour le second et le dernier la diiférence des deux.\n",
    "import datetime \n",
    "\n",
    "def get_attributions(window_backtest_1,window_backtest_2,window_lenght_1,window_lenght_2,mar_value):\n",
    "    \n",
    "            \n",
    "    # Backtest_starting_date :     \n",
    "    backtest_starting_date = datetime.datetime(année_début, mois_début, jour_début)\n",
    "    backtest_starting_date = backtest_starting_date + BDay(1)\n",
    "    backtest_starting_date = datetime.datetime(int(str(backtest_starting_date)[:4]), int(str(backtest_starting_date)[5:7]), int(str(backtest_starting_date)[8:10]))\n",
    "        \n",
    "    # Backtest_ending_date : \n",
    "    backtest_ending_date = datetime.datetime(année_fin,mois_fin,jour_fin)\n",
    "    backtest_ending_date = backtest_ending_date + BDay(1)\n",
    "    backtest_ending_date = datetime.datetime(int(str(backtest_ending_date)[:4]), int(str(backtest_ending_date)[5:7]), int(str(backtest_ending_date)[8:10]))\n",
    "    \n",
    "    for k,portefeuille in zip (range (len(directory_list)),directory_list):\n",
    "        \n",
    "        directory_path_attributions = Liste_for_database_mngt[k] + sub_directory_database_list[0]\n",
    "        Portefeuille = pd.read_excel(directory_list[k])\n",
    "\n",
    "        Portefeuille_list1 = prepare_portefeuille(Portefeuille,window_backtest_1,window_lenght_1,backtest_starting_date,backtest_ending_date)\n",
    "        Portefeuille_list2 = prepare_portefeuille(Portefeuille,window_backtest_2,window_lenght_2,backtest_starting_date,backtest_ending_date)\n",
    "        \n",
    "        Weight_Matrice_1 = pd.read_excel(Liste_for_database_mngt[k] + \"/Weight matrices\" + '/'  + \"{} \".format(TODAY) + \"{} \".format(portefeuille[-16:-5]) + get_weight_name(\"Weight_matrice\",window_backtest_1,mar_value))\n",
    "        Weight_Matrice_2 = pd.read_excel(Liste_for_database_mngt[k] + \"/Weight matrices\" + '/'  + \"{} \".format(TODAY) + \"{} \".format(portefeuille[-16:-5]) + get_weight_name(\"Weight_matrice\",window_backtest_2,mar_value))\n",
    "        \n",
    "        Weight_Matrice_1.set_index('Unnamed: 0',inplace =True)\n",
    "        Weight_Matrice_2.set_index('Unnamed: 0',inplace =True)\n",
    "\n",
    "        Realized_return_1 = get_realized_returns(Portefeuille_list1,Weight_Matrice_1)\n",
    "        Realized_return_2 = get_realized_returns(Portefeuille_list2,Weight_Matrice_2)\n",
    "        \n",
    "        index = len(Realized_return_2) - 5\n",
    "        \n",
    "        plt.figure(figsize = (20,10))\n",
    "        Realized_return_1.plot(colormap='PuRd',figsize = (20,10))\n",
    "        plt.title('Attribution de performance'+ ' {}'.format(portefeuille[-16:-5]) + ' {}'.format(window_backtest_1))\n",
    "        plt.savefig(directory_path_attributions +  \"/\" + 'Attribution de performance'+ ' {}'.format(portefeuille[-16:-5]) + ' {}'.format(window_backtest_1) + \".png\")\n",
    "        \n",
    "        plt.figure(figsize = (20,10))\n",
    "        Realized_return_2.plot(colormap='PuRd',figsize = (20,10))\n",
    "        plt.title('Attribution de performance' + ' {}'.format(portefeuille[-16:-5]) + ' {}'.format(window_backtest_2))\n",
    "        plt.savefig(directory_path_attributions +  \"/\" + 'Attribution de performance' + ' {}'.format(portefeuille[-16:-5]) + ' {}'.format(window_backtest_2) + \".png\")\n",
    "        \n",
    "        plt.figure(figsize = (20,10))\n",
    "        last_df = Realized_return_1[-index:] - Realized_return_2[-index:]\n",
    "        last_df.plot(colormap='PuRd',figsize = (20,10))\n",
    "        plt.title('Attribution de performance' + ' {}'.format(portefeuille[-16:-5]) + ' {}'.format(window_backtest_1) + \" - \" +' {}'.format(window_backtest_2))\n",
    "        plt.savefig(directory_path_attributions + \"/\" + 'Attribution de performance' + ' {}'.format(portefeuille[-16:-5]) + ' {}'.format(window_backtest_1) + \" - \" +' {}'.format(window_backtest_2) + \".png\")\n",
    "        \n",
    "        \n",
    "get_attributions(window_backtest_1,window_backtest_2,window_lenght_1,window_lenght_2,mar_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b9eef-c301-4608-ac94-205df16b28bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
